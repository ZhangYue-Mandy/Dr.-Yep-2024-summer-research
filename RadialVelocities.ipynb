{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Velocity Procedure, Goodman x Goodman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Cougy.\n"
     ]
    }
   ],
   "source": [
    "#Load packages and basic functions.\n",
    "\n",
    "#from YepFunctions import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 18,'lines.linewidth':4})\n",
    "import matplotlib.cm as cm\n",
    "from os.path import exists\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from lmfit import Model #for Azmain's code\n",
    "from PyAstronomy import pyasl\n",
    "from scipy.signal import argrelextrema\n",
    "import time\n",
    "import glob\n",
    "from getpass import getuser\n",
    "\n",
    "print('Working on '+getuser()+'.')\n",
    "\n",
    "# #directories:\n",
    "# ddir='/Users/'+getuser()+'/gsu-thesis/Research/PythonPlots/data2/' #where to access and save your data\n",
    "# pdir='/Users/'+getuser()+'/gsu-thesis/Research/PythonPlots/plots2/' #where to save your plots\n",
    "cdir='/Users/'+getuser()+'/gsu-thesis/Research/chiron/' #reduced chiron data, straight from GSU server\n",
    "# ndir='/Users/Cougy/gsu-thesis/Research/chiron/normalized/' #reduced chiron data, straight from GSU server\n",
    "\n",
    "#Ultimate opendat:\n",
    "def opendatt(dir,filename,spl=''): #dir,'filename'. For opening a data file. Can then send through roundtable.\n",
    "    f=open(dir+filename,'r')\n",
    "    dat=f.readlines()\n",
    "    f.close()\n",
    "    if spl=='':\n",
    "        labels=dat[0][0:-1].split()\n",
    "        dat2=[[a.strip('\\n') for a in d.split()] for d in dat if d[0]!='#']\n",
    "    else:\n",
    "        labels=dat[0][0:-1].split(spl)\n",
    "        dat2=[[a.strip('\\n') for a in d.split(spl)] for d in dat if d[0]!='#']\n",
    "    dat3=[['nan' if a.strip()=='' else a for a in d] for d in dat2]\n",
    "    return [dat3,labels]\n",
    "\n",
    "def opendat(dirr,filename,params,splitchar='',prin='y'): #Use as var,var,var...=opendat(dir,'filename',['keys']).\n",
    "    if splitchar=='':\n",
    "        dat,label=opendatt(dirr,filename)\n",
    "    else:\n",
    "        dat,label=opendatt(dirr,filename,splitchar)  #Get keys by first leaving ['keys'] blank: opendat(dirr,filename,[])\n",
    "    if prin=='y':\n",
    "        print(label)\n",
    "    varrs=[]\n",
    "    for i in range(len(params)):\n",
    "        j=label.index(params[i])\n",
    "        try:\n",
    "            var=np.array([float(d[j]) for d in dat]) #works for float.\n",
    "            varrs.append(var)\n",
    "        except ValueError:\n",
    "            var=[d[j].strip() for d in dat] #works for strings.\n",
    "            varrs.append(var)\n",
    "    if len(params)==1:\n",
    "        varrs=varrs[0]\n",
    "    return varrs\n",
    "\n",
    "def writedat(dirr,filename,pars,label): #.dat auto included. pars as [name,ra,dec] etc.\n",
    "    datp=[[str(a[i]) for a in pars] for i in range(len(pars[0]))]\n",
    "    f=open(dirr+filename+'.dat','w')\n",
    "    print('\\t'.join(label),file=f)\n",
    "    print(label)\n",
    "    for d in datp:\n",
    "        print('\\t'.join(d),file=f)\n",
    "    f.close()\n",
    "    print('It is written: '+filename+'.dat')\n",
    "\n",
    "def hmsdms(ra,dec,splitchar=' '): #input in degrees, output in HH MM S.SSS\n",
    "    H=ra/15.\n",
    "    h=int(H)\n",
    "    M=(H-h)*60.\n",
    "    m=int(M)\n",
    "    s=(M-m)*60.\n",
    "    \n",
    "    DEC=abs(dec)\n",
    "    sign=np.sign(dec)\n",
    "    dd=int(DEC)\n",
    "    d=int(sign*dd)\n",
    "    AM=(DEC-dd)*60.\n",
    "    am=int(AM)\n",
    "    ass=(AM-am)*60.\n",
    "    return str(h)+splitchar+str(m)+splitchar+str(round(s,3))+'\\t'+str(d)+splitchar+str(am)+splitchar+str(round(ass,3))\n",
    "\n",
    "def hmsdms2(ra,dec,splitchar=' '):\n",
    "    RADEC=[hmsdms(ra[i],dec[i],splitchar) for i in range(len(ra))]\n",
    "    return RADEC\n",
    "\n",
    "def dmshms(ra,dec): #input HH:MM:S.SSS, output degrees\n",
    "    if ':' in ra[0]:\n",
    "        splitchar=':'\n",
    "    else:\n",
    "        splitchar=' '\n",
    "    hms=[a.split(splitchar) for a in ra]\n",
    "    h=[float(a[0])*15. for a in hms]\n",
    "    m=[float(a[1])*15./60. for a in hms]\n",
    "    s=[float(a[2])*15./3600. for a in hms]\n",
    "    H=[h[i]+m[i]+s[i] for i in range(len(ra))]\n",
    "    \n",
    "    dms=[a.split(splitchar) for a in dec]\n",
    "    d=[float(a[0]) for a in dms]\n",
    "    am=[float(a[1])/60. for a in dms]\n",
    "    ass=[float(a[2])/3600. for a in dms]\n",
    "    sign=[-1. if a[0]=='-' else 1. for a in dec]\n",
    "    D=[sign[i]*(abs(d[i])+am[i]+ass[i]) for i in range(len(ra))]\n",
    "    return H,D\n",
    "\n",
    "def dmshms1(ra,dec): #input HH:MM:S.SSS, output degrees\n",
    "    if ':' in ra:\n",
    "        splitchar=':'\n",
    "    else:\n",
    "        splitchar=' '\n",
    "    hms=ra.split(splitchar)\n",
    "    h=float(hms[0])*15.\n",
    "    m=float(hms[1])*15./60.\n",
    "    s=float(hms[2])*15./3600.\n",
    "    H=h+m+s\n",
    "    \n",
    "    dms=dec.split(splitchar)\n",
    "    d=float(dms[0])\n",
    "    am=float(dms[1])/60.\n",
    "    ass=float(dms[2])/3600.\n",
    "    if dec[0]=='-':\n",
    "        sign=-1.\n",
    "    else:\n",
    "        sign=1.\n",
    "    D=sign*(abs(d)+am+ass)\n",
    "    return H,D\n",
    "\n",
    "def erm(val,err): #list,list\n",
    "    v=np.array(val)\n",
    "    e=np.array(err)\n",
    "    w=1.0/e**2.0\n",
    "    avg=np.nansum(w*v)/np.nansum(w)\n",
    "    avgerr=1.0/np.sqrt(np.nansum(w))\n",
    "    return avg,avgerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#crosscorrRV routine with normalization:\n",
    "\n",
    "import numpy as np\n",
    "from PyAstronomy.pyaC import pyaErrors as PE\n",
    "from PyAstronomy.pyasl import _ic\n",
    "from lmfit import Model #for Azmain's code\n",
    "\n",
    "def crosscorrRVn(w, f, tw, tf, rvmin, rvmax, drv, mode=\"normdop\", skipedge=0, edgeTapering=None):\n",
    "    \"\"\"\n",
    "        Cross-correlate a spectrum with a template.\n",
    "        \n",
    "        The algorithm implemented here works as follows: For\n",
    "        each RV shift to be considered, the wavelength axis\n",
    "        of the template is shifted, either linearly or using\n",
    "        a proper Doppler shift depending on the `mode`. The\n",
    "        shifted template is then linearly interpolated at\n",
    "        the wavelength points of the observation\n",
    "        (spectrum) to calculate the cross-correlation function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        w : array\n",
    "                The wavelength axis of the observation.\n",
    "        f : array\n",
    "                The flux axis of the observation.\n",
    "        tw : array\n",
    "                The wavelength axis of the template.\n",
    "        tf : array\n",
    "                The flux axis of the template.\n",
    "        rvmin : float\n",
    "                Minimum radial velocity for which to calculate\n",
    "                the cross-correlation function [km/s].\n",
    "        rvmax : float\n",
    "                Maximum radial velocity for which to calculate\n",
    "                the cross-correlation function [km/s].\n",
    "        drv : float\n",
    "                The width of the radial-velocity steps to be applied\n",
    "                in the calculation of the cross-correlation\n",
    "                function [km/s].\n",
    "        mode : string, {lin, doppler}, optional\n",
    "                The mode determines how the wavelength axis will be\n",
    "                modified to represent a RV shift. If \"lin\" is specified,\n",
    "                a mean wavelength shift will be calculated based on the\n",
    "                mean wavelength of the observation. The wavelength axis\n",
    "                will then be shifted by that amount. If \"doppler\" is\n",
    "                specified (the default), the wavelength axis will\n",
    "                properly be Doppler-shifted.\n",
    "        skipedge : int, optional\n",
    "                If larger zero, the specified number of bins will be\n",
    "                skipped from the begin and end of the observation. This\n",
    "                may be useful if the template does not provide sufficient\n",
    "                coverage of the observation.\n",
    "        edgeTapering : float or tuple of two floats\n",
    "                If not None, the method will \"taper off\" the edges of the\n",
    "                observed spectrum by multiplying with a sine function. If a float number\n",
    "                is specified, this will define the width (in wavelength units)\n",
    "                to be used for tapering on both sides. If different tapering\n",
    "                widths shall be used, a tuple with two (positive) numbers\n",
    "                must be given, specifying the width to be used on the low- and\n",
    "                high wavelength end. If a nonzero 'skipedge' is given, it\n",
    "                will be applied first. Edge tapering can help to avoid\n",
    "                edge effects (see, e.g., Gullberg and Lindegren 2002, A&A 390).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dRV : array\n",
    "                The RV axis of the cross-correlation function. The radial\n",
    "                velocity refer to a shift of the template, i.e., positive\n",
    "                values indicate that the template has been red-shifted and\n",
    "                negative numbers indicate a blue-shift of the template.\n",
    "                The numbers are given in km/s.\n",
    "        CC : array\n",
    "                The cross-correlation function.\n",
    "    \"\"\"\n",
    "    if not _ic.check[\"scipy\"]:\n",
    "        raise(PE.PyARequiredImport(\"This routine needs scipy (.interpolate.interp1d).\", \\\n",
    "                                                             where=\"crosscorrRV\", \\\n",
    "                                                             solution=\"Install scipy\"))\n",
    "    import scipy.interpolate as sci\n",
    "    # Copy and cut wavelength and flux arrays\n",
    "    w, f = w.copy(), f.copy()\n",
    "    if skipedge > 0:\n",
    "        w, f = w[skipedge:-skipedge], f[skipedge:-skipedge]\n",
    "    \n",
    "    if edgeTapering is not None:\n",
    "        # Smooth the edges using a sine\n",
    "        if isinstance(edgeTapering, float):\n",
    "            edgeTapering = [edgeTapering, edgeTapering]\n",
    "        if len(edgeTapering) != 2:\n",
    "            raise(PE.PyAValError(\"'edgeTapering' must be a float or a list of two floats.\", \\\n",
    "                                                     where=\"crosscorrRV\"))\n",
    "        if edgeTapering[0] < 0.0 or edgeTapering[1] < 0.0:\n",
    "            raise(PE.PyAValError(\"'edgeTapering' must be (a) number(s) >= 0.0.\", \\\n",
    "                                                     where=\"crosscorrRV\"))\n",
    "        # Carry out edge tapering (left edge)\n",
    "        indi = np.where(w < w[0]+edgeTapering[0])[0]\n",
    "        f[indi] *= np.sin((w[indi] - w[0])/edgeTapering[0]*np.pi/2.0)\n",
    "        # Carry out edge tapering (right edge)\n",
    "        indi = np.where(w > (w[-1]-edgeTapering[1]))[0]\n",
    "        f[indi] *= np.sin((w[indi] - w[indi[0]])/edgeTapering[1]*np.pi/2.0 + np.pi/2.0)\n",
    "    \n",
    "    # Speed of light in km/s\n",
    "    c = 299792.458\n",
    "    # Check order of rvmin and rvmax\n",
    "    if rvmax <= rvmin:\n",
    "        raise(PE.PyAValError(\"rvmin needs to be smaller than rvmax.\",\n",
    "                                                 where=\"crosscorrRV\", \\\n",
    "                                                 solution=\"Change the order of the parameters.\"))\n",
    "    # Check whether template is large enough\n",
    "    if mode == \"lin\":\n",
    "        meanWl = np.mean(w)\n",
    "        dwlmax = meanWl * (rvmax/c)\n",
    "        dwlmin = meanWl * (rvmin/c)\n",
    "        if (tw[0] + dwlmax) > w[0]:\n",
    "            raise(PE.PyAValError(\"The minimum wavelength is not covered by the template for all indicated RV shifts.\", \\\n",
    "                                                     where=\"crosscorrRV\", \\\n",
    "                                                     solution=[\"Provide a larger template\", \"Try to use skipedge\"]))\n",
    "        if (tw[-1] + dwlmin) < w[-1]:\n",
    "            raise(PE.PyAValError(\"The maximum wavelength is not covered by the template for all indicated RV shifts.\", \\\n",
    "                                                     where=\"crosscorrRV\", \\\n",
    "                                                     solution=[\"Provide a larger template\", \"Try to use skipedge\"]))\n",
    "    elif mode == \"doppler\" or mode == 'normdop':\n",
    "        # Ensure that the template covers the entire observation for all shifts\n",
    "        maxwl = tw[-1] * (1.0+rvmin/c)\n",
    "        minwl = tw[0] * (1.0+rvmax/c)\n",
    "        if minwl > w[0]:\n",
    "            raise(PE.PyAValError(\"The minimum wavelength is not covered by the template for all indicated RV shifts.\", \\\n",
    "                                                     where=\"crosscorrRV\", \\\n",
    "                                                     solution=[\"Provide a larger template\", \"Try to use skipedge\"]))\n",
    "        if maxwl < w[-1]:\n",
    "            raise(PE.PyAValError(\"The maximum wavelength is not covered by the template for all indicated RV shifts.\", \\\n",
    "                                                     where=\"crosscorrRV\", \\\n",
    "                                                     solution=[\"Provide a larger template\", \"Try to use skipedge\"]))\n",
    "    else:\n",
    "        raise(PE.PyAValError(\"Unknown mode: \" + str(mode), \\\n",
    "                                                 where=\"crosscorrRV\", \\\n",
    "                                                 solution=\"See documentation for available modes.\"))\n",
    "    # Calculate the cross correlation\n",
    "    drvs = np.arange(rvmin, rvmax, drv)\n",
    "    cc = np.zeros(len(drvs))\n",
    "    for i, rv in enumerate(drvs):\n",
    "        if mode == \"lin\":\n",
    "            # Shift the template linearly\n",
    "            fi = sci.interp1d(tw+meanWl*(rv/c), tf)\n",
    "            cc[i] = np.sum(f * fi(w))\n",
    "        elif mode == \"doppler\":\n",
    "            # Apply the Doppler shift\n",
    "            fi = sci.interp1d(tw*(1.0 + rv/c), tf)\n",
    "            cc[i] = np.sum(f * fi(w))\n",
    "        # Shifted template evaluated at location of spectrum\n",
    "        elif mode == \"normdop\":\n",
    "            # Apply the Doppler shift\n",
    "            fi = sci.interp1d(tw*(1.0 + rv/c), tf)\n",
    "        # Shifted template evaluated at location of spectrum\n",
    "            cc[i] = 1./float(len(w)-skipedge)*np.sum((f-np.mean(f)) * (fi(w)-np.mean(fi(w))))/np.sqrt(np.var(f)*np.var(fi(w)))\n",
    "    return drvs, cc\n",
    "\n",
    "def sigmavg(dat,head,w,f,fn): #fits data, fits header, wavelength, unnormalized flux, normalized flux; Goodman\n",
    "    #w,f=wf(dat,o)\n",
    "    gain=float(head['GAIN'])\n",
    "    RN=float(head['RDNOISE'])\n",
    "#     if head['MODES'].split(',')[int(head['MODE'])].strip()=='fiber':\n",
    "#         K=2.5\n",
    "#     elif head['MODES'].split(',')[int(head['MODE'])].strip()=='slicer':\n",
    "#         K=9.\n",
    "    K=5 #pixels binned across spectral order. Here, it's...? No clue.\n",
    "    SNR=np.array(f)*gain/np.sqrt(np.array(f)*gain+K*RN**2.)\n",
    "    c=299792.458 #km/s\n",
    "    dfdw=deriv(w,fn)\n",
    "    Sigmav=1./np.sqrt(np.nansum((np.array(dfdw)*np.array(w)*np.array(SNR)/c)**2.))\n",
    "    return Sigmav\n",
    "\n",
    "#By chain rule: df/dv = df/dw * w/c. So can use df/dw derivative and multiply by w/c for deriv at each pixel.\n",
    "def deriv(X,Y): #numerical\n",
    "    #middle: 2 derivs on either side of pixel, then average\n",
    "    x0=np.array(X[:-2])\n",
    "    y0=np.array(Y[:-2])\n",
    "    x1=np.array(X[1:-1])\n",
    "    y1=np.array(Y[1:-1])\n",
    "    x2=np.array(X[2:])\n",
    "    y2=np.array(Y[2:])\n",
    "    dydx_m=((y1-y0)/(x1-x0)+(y2-y1)/(x1-x0))/2.\n",
    "    #print(len(dydx_m))\n",
    "    #ends: just do 1 deriv\n",
    "    dydx_b=(Y[1]-Y[0])/(X[1]-X[0])\n",
    "    dydx_e=(Y[-1]-Y[-2])/(X[-1]-X[-2])\n",
    "    #combine:\n",
    "    dydx=[dydx_b,]+list(dydx_m)+[dydx_e,]\n",
    "    #print(len(dydx))\n",
    "    return dydx\n",
    "\n",
    "#barycentric correction\n",
    "def bcvg(head): #for Goodman\n",
    "    #RA,Dec,expt,jd (jd of middle of exposure time)\n",
    "\n",
    "    # Coordinates of SOAR telescope for Goodman\n",
    "    longitude = -1.*(70.+44./60.+1.11/3600.) #degrees, E=+,W=-\n",
    "    latitude = -30.-14./60.-16.41/3600. #degrees\n",
    "    altitude = 2713. #meters\n",
    "    \n",
    "    expt=head['EXPTIME'] #exposure time\n",
    "    #print(expt,type(expt),type(Time(head['DATE-OBS']).jd))\n",
    "    JD=Time(head['DATE-OBS']).jd+expt/2./60./24. #Julian day of middle of exposure, UT\n",
    "    # Coordinates in degrees (J2000) for pyas1\n",
    "    RA=[float(d)*15. for d in head['RA'].split(':')] #RA, degrees\n",
    "    DEC=[float(d) for d in head['DEC'].split(':')] #Dec\n",
    "    if '-' in head['DEC']:\n",
    "        sign=-1.\n",
    "    else:\n",
    "        sign=1.\n",
    "    ra2000 = RA[0]+RA[1]/60.+RA[2]/3600. #RA\n",
    "    dec2000 = sign*(abs(DEC[0])+DEC[1]/60.+DEC[2]/3600.) #Dec\n",
    "\n",
    "    # Barycentric velocity correction\n",
    "    cor = pyasl.helcorr(longitude, latitude, altitude,ra2000, dec2000, JD)[0]\n",
    "    return cor\n",
    "\n",
    "def gaussian(x, amp, cen, wid): # Gaussian model\n",
    "    \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "    return ((1 * amp) / (np.sqrt(2*np.pi) * wid)) * np.exp(-(x-cen)**2 / (2*wid**2)) \n",
    "gmodel = Model(gaussian)\n",
    "\n",
    "#new sval 2024 (allow IV), let's try only up to K7, rest go to \"10\" to change class. K7 goes to \"8.\"\n",
    "def sval(ss): #'spt'\n",
    "    def vs(s): #v from s, for single value\n",
    "        if s=='nan':\n",
    "            v= np.float('nan')\n",
    "            return np.float('nan')\n",
    "        else:\n",
    "            val=60-['O','B','A','F','G','K','M','L','T','Y'].index(s[0])*10+(10-float(s[1:].strip('V').strip('I')))\n",
    "        if s[0] in ['M','L','T','Y']: #M gets set back because of K; K7 should be right next to M0\n",
    "            val+=2\n",
    "        if 'III' in s:\n",
    "            v= val-100.\n",
    "        elif 'I' in s and 'III' not in s and 'V' not in s:\n",
    "            v= val-200.\n",
    "        else:\n",
    "            v= val\n",
    "        return v\n",
    "    if type(ss)==str:\n",
    "        final=vs(ss)\n",
    "    if type(ss)==list or type(ss)==type(np.array([1])):\n",
    "        final=[]\n",
    "        for i in range(len(ss)):\n",
    "            s=ss[i]\n",
    "            v=vs(s)\n",
    "            final.append(v)\n",
    "    return final\n",
    "\n",
    "def sptfromsval(s): #'spt'\n",
    "    obafgkm=['O','B','A','F','G','K','M']\n",
    "    if s<=12:\n",
    "        s-=2 #handle the Ms\n",
    "    if s>=0:\n",
    "        lum='V'\n",
    "        S=int(s/10.)\n",
    "    elif s<0 and s>=-100:\n",
    "        lum='III'\n",
    "        S=int((s+100.)/10.)\n",
    "    elif s<-100:\n",
    "        lum='I'\n",
    "        S=int((s+200.)/10.)\n",
    "    else:\n",
    "        print('Error with luminosity class.')\n",
    "    clas=str(round(10-(s-float(10*S)),1)).replace('.0','')\n",
    "    if round(10-(s-float(10*S)),1)==10:\n",
    "        clas='0'\n",
    "        S-=1\n",
    "    oba=obafgkm[6-S]\n",
    "    return oba+clas+lum\n",
    "\n",
    "#retrieve rv,vsini,bcv from LogCruncher standards summary file\n",
    "def refv(stdname):\n",
    "    name,vsini,vsinierr,rv,rverr=opendat(cdir,'standards/standards_metadata.dat',['#name','vsini', 'vsinierr', 'rv', 'rverr'],splitchar='\\t',prin='n')\n",
    "    #bname,barycorr=opendat2(cdir,'standards/CHIRON_standards_bestobs.dat',['name','barycorr'])\n",
    "    i=name.index(stdname)\n",
    "    #j=bname.index(stdname)\n",
    "    return vsini[i],vsinierr[i],rv[i],rverr[i]\n",
    "\n",
    "def refspt(stdname):\n",
    "    name,spt=opendat(cdir,'standards/standards_metadata.dat',['#name','spt'],splitchar='\\t',prin='n')\n",
    "    i=name.index(stdname)\n",
    "    return spt[i]\n",
    "\n",
    "def vrotcombo(vstd,vbroad): #\"adds\" vsinis to get total vsini\n",
    "    x=vstd\n",
    "    y=vbroad\n",
    "    r=np.sqrt(x**2.+y**2.)\n",
    "    theta=np.arctan(y/x)\n",
    "    v0=0.044*r #deflection from circle\n",
    "    if theta<=np.pi/4.:\n",
    "        vtot=r+4.*v0/np.pi*theta\n",
    "    if theta>np.pi/4.:\n",
    "        vtot=r-4.*v0/np.pi*theta+2.*v0\n",
    "    return vtot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#check', 'number', 'name', 'ra', 'dec', 'V', 'spt']\n",
      "GJ83.1 : M4.5V M4.5V\n",
      "HD217357 : K7V K7V\n",
      "HD42581 : M1V M1V\n",
      "HD36003 : K5V K5V\n",
      "HIP18280 : M0V M0V\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "\n",
    "#main dir:\n",
    "gdir='/Users/Cougy/Desktop/_AgnesScottCollege/SummerResearch/2024Summer/Dr.-Yep-2024-summer-research/'\n",
    "#Goodman normalized spectra:\n",
    "gndir=gdir+'/GoodmanNormBest/'\n",
    "\n",
    "# get all files in their various locations:\n",
    "files=glob.glob(gndir+'*.fits')\n",
    "#print(files)\n",
    "fnamest=[a.split('/')[-1][2:].replace('.fits','').replace('dot','.') for a in files]\n",
    "fnames=[a.split('/')[-1][2:].replace('.fits','').replace('_target_1','').replace('_target_2','').replace('_target_3','').replace('dot','.') for a in files]\n",
    "#print('fnames',fnames) #from files\n",
    "\n",
    "#open my metadata file\n",
    "mnames,ras,decs,Vs,spts=opendat('','Goodman2020B_AYep_TargetChecklist.txt',['name', 'ra', 'dec', 'V', 'spt'],splitchar='\\t')\n",
    "#print('mnames',mnames)\n",
    "\n",
    "stds=[a for a in fnames if a[0]!='C']\n",
    "stdspts=[spts[mnames.index(n)] for n in stds]\n",
    "ssval=[sval(a) for a in stdspts]\n",
    "#print(stds)\n",
    "\n",
    "for i in range(len(stds)):\n",
    "    print(stds[i],':',stdspts[i],refspt(stds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test:\n",
    "# name='GJ83.1'\n",
    "# stdname='HD42581'\n",
    "\n",
    "# pltcc='y'\n",
    "# rvcent0=0\n",
    "# vsinistart0=0\n",
    "# skipedge0=0\n",
    "# prin='y'\n",
    "# plotyn='y'\n",
    "\n",
    "def fitvsinilite(name,stdname,rvcent0=0,vsinistart0=0,skipedge0=0,prin='n',plotyn='n',pltcc='n'): #returns the essentials.\n",
    "    # One target against one standard:\n",
    "    #def fitvsinilite(name,stdname,rvcent0=0,vsinistart0=0,skipedge0=0,prin='n',plotyn='n',pltcc='n'): #returns the essentials.\n",
    "\n",
    "    #For standards test, you don't account for each standard's uncert.\n",
    "    #target:\n",
    "    hdu=fits.open(gndir+'n_'+name+'.fits') #.fits data\n",
    "    dat=hdu[0].data\n",
    "    head=hdu[0].header\n",
    "    hdu.close()\n",
    "    bc=bcvg(head) #barycentric correction\n",
    "    w,f=dat #total spectrum\n",
    "    #unnorm for sigmav\n",
    "    wfunfile=head['WFUNFILE']\n",
    "    hdu=fits.open(gdir+wfunfile) #.fits data\n",
    "    fun=hdu[0].data[1] #unnorm spectrum\n",
    "    hdu.close()\n",
    "\n",
    "    #telluric=[[6275,6315],[6470,6530],[6570,6580]]\n",
    "    #dodge telluric:\n",
    "    regions=[[6000,6275],[6315,6470],[6580,6800]]\n",
    "    ws=[[w[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    fs=[[f[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    funs=[[fun[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    svs=[sigmavg(dat,head,ws[o],funs[o],fs[o]) for o in range(len(fs))]\n",
    "    del w\n",
    "    del f\n",
    "    del fun\n",
    "\n",
    "    #standard:\n",
    "    hdu=fits.open(gndir+'n_'+stdname+'.fits') #.fits data\n",
    "    dat0=hdu[0].data\n",
    "    head0=hdu[0].header\n",
    "    hdu.close()\n",
    "    bc0=bcvg(head0) #barycentric correction\n",
    "    w,f=dat0 #total spectrum\n",
    "    #unnorm for sigmav\n",
    "    wfunfile=head0['WFUNFILE']\n",
    "    hdu=fits.open(gdir+wfunfile) #.fits data\n",
    "    fun=hdu[0].data[1] #unnorm spectrum\n",
    "    hdu.close()\n",
    "    #data for standard:\n",
    "    vsini0,vsini0err,rv0,rv0err=refv(stdname) #metadata\n",
    "    stdspt=refspt(stdname)\n",
    "\n",
    "    ws0=[[w[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    fs0=[[f[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    funs0=[[fun[i] for i in range(len(w)) if w[i]>=t[0] and w[i]<t[1]] for t in regions] #put on known good regions.\n",
    "    svs0=[sigmavg(dat0,head0,ws0[o],funs0[o],fs0[o]) for o in range(len(fs0))]\n",
    "    del w\n",
    "    del f\n",
    "    del fun\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(sum(ws,[]),sum(fs,[]))\n",
    "#     plt.xlabel('Wavelength (A)')\n",
    "#     plt.ylabel('Normalized Flux')\n",
    "\n",
    "    #print((w[1]-w[0])*20)\n",
    "    dw=1.6 #2.8 #what is this based on??? 1.6 for CHIRON fiber, but why???? 20x wavelength res? Kinda.\n",
    "\n",
    "    os=list(range(len(ws0)))\n",
    "    #os=[0,1] #region 2 is too small\n",
    "    #print('os',os)\n",
    "\n",
    "    print('\\nFor target',name,'against standard',stdname,'(rv = '+str(rv0)+' km/s, vsini = '+str(vsini0)+' km/s)')\n",
    "    print('barycorr, target: ',bc,'km/s, standard:',bc0,'km/s\\n')\n",
    "\n",
    "    #default starting skipedge and edge tapering\n",
    "    sk=40\n",
    "    et=10\n",
    "\n",
    "    # std+bc0 should put std at std's heliocentric rv0.\n",
    "    # so, std as-is is really at rv0-bc0.\n",
    "    # meanwhile, target+bc should put target at rv.\n",
    "    # so, target as-is is really at rv-bc.\n",
    "    # crosscorrRVn shifts the template (the std), so RVdiff is (red)shift needed to align std with target.\n",
    "    # so rv0-bc0+RVdiff = rv-bc (for std as-is shifted to target as-is).\n",
    "    # the velocity difference between the as-is spectra, then, is RVdiff=(rv-bc)-(rv0-bc0)=rv-rv0-bc+bc0.\n",
    "    # what we want is the rv of the target: rv = RVdiff+rv0+bc-bc0\n",
    "    # rv = rv0+RVdiff+bc-bc0\n",
    "\n",
    "    # start at best guess, basically at everything-but-RVdiff: If std and targ are within 100 km/s, should be fine.\n",
    "    rvcent00=rv0+rvcent0+bc-bc0\n",
    "\n",
    "    rvs,vsinis=[],[]\n",
    "\n",
    "    #pick vwindow for rv and vsini, based on order 1\n",
    "    vwins=[]\n",
    "    if pltcc=='y':\n",
    "        ccs=[]\n",
    "    preos=[1]\n",
    "    for i in preos: #my red Goodman has 3 nonuniform \"orders\"\n",
    "        o=i\n",
    "        w,f=np.array(ws[i]),np.array(fs[i])-1. #pyasl code wants spectra normalized to 0! Weird.\n",
    "        w0,f0=np.array(ws0[i]),np.array(fs0[i])-1. #\"\"\n",
    "\n",
    "        rv, cc = crosscorrRVn(w, f, w0, f0, rvcent00-200., rvcent00+200.,dw,skipedge=sk+int(0.5*vsinistart0)+skipedge0,edgeTapering=et+0.25*vsinistart0) #The less skipedge, the better. edgeTapering seems happy near 10.??\n",
    "        maxind = np.argmax(cc)\n",
    "        if pltcc=='y':\n",
    "            ccs.append(cc)\n",
    "        try:\n",
    "            min1=np.max([a for a in argrelextrema(cc,np.less)[0] if a<maxind])\n",
    "            min2=np.min([a for a in argrelextrema(cc,np.less)[0] if a>maxind])\n",
    "            vwin=np.max([(min2-min1)/4.,4.]) #4 is the minimum. /4 because otherwise too broad or gaussian fits poorly\n",
    "            vwins.append(vwin)\n",
    "        except ValueError:\n",
    "            print('order',i,'could not find peak or neighboring minima.')\n",
    "            print([a for a in argrelextrema(cc,np.less)[0] if a<maxind])\n",
    "            print([a for a in argrelextrema(cc,np.less)[0] if a>maxind])\n",
    "\n",
    "    vwindow=np.nanmax([np.median(vwins),8.])\n",
    "    rvcent=rv[maxind]\n",
    "    vsinistart=np.max([vwindow-29.,vsinistart0])\n",
    "    print('vsini window',vwindow,', vsini start',vsinistart,', rv cent',rvcent)\n",
    "\n",
    "    if pltcc=='y':\n",
    "        for i in range(len(preos)):\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.title('cross-corr of order '+str(preos[i]))\n",
    "            plt.plot(ccs[i])\n",
    "            plt.ylabel('norm\\'d cc')\n",
    "            plt.xlabel('index')\n",
    "            plt.plot([np.argmax(ccs[i])-int(vwindow+1.0*vsinistart),np.argmax(ccs[i])+int(vwindow+1.0*vsinistart)],[ccs[i][np.argmax(ccs[i])]*0.5,ccs[i][np.argmax(ccs[i])]*0.5])\n",
    "\n",
    "    #find good approx. vsini and refine rvdiff\n",
    "    rvdiffs,vsinibroads=[],[]\n",
    "    V = np.linspace(0+vsinistart,60+vsinistart,10) # collection of vsini. Ultimately works for up to ~60+30 = 90 km/s of broadening.\n",
    "    for i in preos: #[0,]:\n",
    "        o=i\n",
    "        w,f=np.array(ws[i]),np.array(fs[i])-1. #pyasl code wants spectra normalized to 0! Weird.\n",
    "        w0,f0=np.array(ws0[i]),np.array(fs0[i])-1. #\"\"\n",
    "        rv, cc = crosscorrRVn(w, f, w0, f0, rvcent-100., rvcent+100.,dw,skipedge=sk+int(0.5*vsinistart)+skipedge0,edgeTapering=et+0.25*vsinistart) #The less skipedge, the better. edgeTapering seems happy near 10.??\n",
    "        maxind = np.argmax(cc)\n",
    "        #vsini\n",
    "        xnew = np.linspace(w0[0],w0[-1],len(w0)) # uniform wavelength spacing\n",
    "        ynew = np.interp(xnew,w0,f0) #standard spectrum interpolated to uniform wavelength spacing\n",
    "        hs=[]\n",
    "        for v in V: # empirical vsini relation from broadened template\n",
    "            if v==0:\n",
    "                v=0.01\n",
    "            bflux = pyasl.rotBroad(xnew, ynew, 0.6, v) # flux of broadened spectrum\n",
    "            rV, cC = crosscorrRVn(xnew, bflux, xnew, ynew,-1*int(vwindow+1.0*vsinistart),int(vwindow+1.0*vsinistart),dw,skipedge=int(sk/2+0.5*vsinistart),edgeTapering=et+0.25*vsinistart) #need to increase for faster rotation? Keep checking. CG 1's F star needs more skip and taper.\n",
    "            result = gmodel.fit(cC, x=rV, amp=1., cen=0., wid=1.)\n",
    "            h = result.best_values #gauss width of std with rot'l broadening of v km/s\n",
    "            hs.append(h['wid'])\n",
    "        width = hs #np.genfromtxt(file1) # use empirical relation to get RV and vsini\n",
    "        rvmin = rv[maxind] - (vwindow+1.0*vsinistart)\n",
    "        rvmax = rv[maxind] + (vwindow+1.0*vsinistart)\n",
    "        rv2, cc2 = crosscorrRVn(w, f, w0, f0, rvmin, rvmax,dw,skipedge=int(sk/2+0.5*vsinistart)+skipedge0,edgeTapering=et+0.25*vsinistart) \n",
    "        maxind = np.argmax(cc2)\n",
    "\n",
    "        if pltcc=='y':\n",
    "                plt.figure(figsize=(5,5))\n",
    "                plt.title('cross-corr of order '+str(o))\n",
    "                plt.plot(rv2,cc2)\n",
    "                plt.ylabel('norm\\'d cc')\n",
    "                plt.xlabel('rv')\n",
    "                plt.plot([rvmin,rvmax],[cc2[np.argmax(cc2)]*0.5,cc2[np.argmax(cc2)]*0.5])\n",
    "\n",
    "        try:\n",
    "            result = gmodel.fit(cc2, x=rv2, amp=cc2[maxind], cen=rv2[maxind], wid=1.) #gauss width of actual target spectrum\n",
    "            h = result.best_values\n",
    "            RVdiff = h['cen'] #really the rv diff between standard and target.\n",
    "            vsini = np.interp(h['wid'],width,V) #just the broadening\n",
    "            #if vsini is considerably smaller than vsini_std, discard the measurement:\n",
    "            #if vsini==vsini0:\n",
    "            #    vsini=float('nan') #but this doesn't seem to work with my V intervals.\n",
    "            #rv shouldn't change from day to day, month to month, as earth moves. So rv must be relative to point of rest.\n",
    "            #bcv is motion of earth towards a star. So star's motion away from rest point is actually obs'd motion of star + calc'd motion of earth toward star.\n",
    "            #u: uncorrected, c: corrected. 0:standard\n",
    "            #rvc= rv0c + rvcdiff = rv0c + (rvc - rv0c) = rv0c + ((rvu + bc) - (rv0u + bc0)) = rv0c + (rvu - rv0u) + bc - bc0\n",
    "            #RV_true= rv0 + RVdiff + bc - bc0\n",
    "            rvdiffs.append(RVdiff)\n",
    "            vsinibroads.append(vsini)\n",
    "        except ValueError:\n",
    "            print('Failed to fit Gaussian to order '+str(o)+'.')\n",
    "            rvdiffs.append(np.float('nan'))\n",
    "            vsinibroads.append(np.float('nan'))\n",
    "    #Remove outliers based on median and std of middle quartile\n",
    "    midrv=np.median(rvdiffs)\n",
    "    midstd=np.std(np.array([d for d in rvdiffs if d>np.percentile(rvdiffs,25) and d<np.percentile(rvdiffs,75)]))\n",
    "    stdfac=3.\n",
    "    rvres=10. #km/s, arbitrary at the moment\n",
    "    rmin=midrv-stdfac*midstd if stdfac*midstd>rvres else midrv-rvres\n",
    "    rmax=midrv+stdfac*midstd if stdfac*midstd>rvres else midrv+rvres\n",
    "    rvx=np.array([d for d in rvdiffs if d>rmin and d<rmax])\n",
    "    bados=[os[i] for i in range(len(rvs)) if rvs[i]<=rmin or rvs[i]>=rmax]\n",
    "    #weighted rv\n",
    "    weights0=1./np.array(svs0)**2.\n",
    "    weights0x=np.array([weights0[i] for i in range(len(rvdiffs)) if rvdiffs[i]>rmin and rvdiffs[i]<rmax])\n",
    "    #normalize the weights\n",
    "    weights0xn=weights0x/sum(weights0x)\n",
    "    #rv\n",
    "    rvxw=sum(rvx*weights0xn)\n",
    "    #vsini\n",
    "    vsinix=np.array([vsinibroads[i] for i in range(len(rvdiffs)) if rvdiffs[i]>rmin and rvdiffs[i]<rmax])\n",
    "    #normalize the weights\n",
    "    weights0xx=[weights0x[i] if np.isnan(vsinix[i])==False else float('nan') for i in range(len(weights0x))] #keep if vsini any good\n",
    "    weights0xxn=weights0xx/np.nansum(weights0xx)\n",
    "    vsinixw=np.nansum(vsinix*weights0xxn)\n",
    "\n",
    "    #do full analysis with very tailored rvcent,vsinistart\n",
    "    rvcent=rvxw\n",
    "    vsinistart=np.max((vsinixw-10,0))\n",
    "    print('new vsini start',vsinistart,', new rv cent',rvcent)\n",
    "    V = np.linspace(0+vsinistart,20+vsinistart,10) # !!!!! collection of vsini. Winner: 20/10. !!!!!\n",
    "    for i in range(len(os)): #[0,]:\n",
    "        o=os[i]\n",
    "        print(o)\n",
    "        w,f=np.array(ws[i]),np.array(fs[i])-1. #pyasl code wants spectra normalized to 0! Weird.\n",
    "        w0,f0=np.array(ws0[i]),np.array(fs0[i])-1. #\"\"\n",
    "        rv, cc = crosscorrRVn(w, f, w0, f0, rvcent-10.-int(vsinistart/2.), rvcent+10.+int(vsinistart/2.),dw,skipedge=sk+int(0.5*vsinistart)+skipedge0,edgeTapering=et+0.25*vsinistart) #The less skipedge, the better. edgeTapering seems happy near 10.??\n",
    "        maxind = np.argmax(cc)\n",
    "        #vsini\n",
    "        xnew = np.linspace(w0[0],w0[-1],len(w0)) # !!!!! uniform wavelength spacing. Winner: original resolution. !!!!!\n",
    "        ynew = np.interp(xnew,w0,f0)\n",
    "        hs=[]\n",
    "        for v in V: # empirical vsini relation from broadened template\n",
    "            if v==0:\n",
    "                v=0.01\n",
    "            bflux = pyasl.rotBroad(xnew, ynew, 0.6, v) # flux of broadened spectrum \n",
    "            rV, cC = crosscorrRVn(xnew, bflux, xnew, ynew,-1*int(vwindow+1.0*vsinistart),int(vwindow+1.0*vsinistart),dw,skipedge=int(sk/2+0.5*vsinistart),edgeTapering=et+0.25*vsinistart) #need to increase for faster rotation? Keep checking. CG 1's F star needs more skip and taper.\n",
    "            result = gmodel.fit(cC, x=rV, amp=1., cen=0., wid=1.)\n",
    "            h = result.best_values\n",
    "            hs.append(h['wid'])\n",
    "        ###width = hs #np.genfromtxt(file1) # use empirical relation to get RV and vsini\n",
    "        width=[hs[i] for i in range(len(hs)-1) if hs[i+1]-hs[i]>0.01]+[hs[-1],] #delete vertical front if present\n",
    "        V2=[V[i] for i in range(len(hs)-1) if hs[i+1]-hs[i]>0.01]+[V[-1],] #match width\n",
    "        rvmin = rv[maxind] - (vwindow+1.0*vsinistart)\n",
    "        rvmax = rv[maxind] + (vwindow+1.0*vsinistart)\n",
    "        rv2, cc2 = crosscorrRVn(w, f, w0, f0, rvmin, rvmax,dw,skipedge=int(sk/2+0.5*vsinistart)+skipedge0,edgeTapering=et+0.25*vsinistart) \n",
    "        maxind = np.argmax(cc2)\n",
    "        try:\n",
    "            result = gmodel.fit(cc2, x=rv2, amp=cc2[maxind], cen=rv2[maxind], wid=1.) \n",
    "            h = result.best_values\n",
    "            RVdiff = h['cen'] #really the rv diff between standard and target, target-standard.\n",
    "            RV_true= rv0 + RVdiff + bc - bc0\n",
    "            if prin=='y':\n",
    "                prince='rv diff '+str(round(RVdiff,3))+', rv = '+str(round(RV_true,5))+' km/s'\n",
    "            rvs.append(RV_true)\n",
    "            ###vsini = np.interp(h['wid'],width,V+vsini0) #map to vsini unbroadened = vsini_std\n",
    "            ###new vsini###\n",
    "            if h['wid']>np.min(width) and h['wid']<np.max(width):\n",
    "                vsinibroad = np.interp(h['wid'],width,V2) #map to vsini unbroadened = vsini_std. #based on the relation of gauss widths to v broadenings + vsini_std generated earlier, the actual width of the target should correspond to THIS vsini.\n",
    "                vsini=vrotcombo(vsini0,vsinibroad)\n",
    "                fitpass='y'\n",
    "                if prin=='y':\n",
    "                    print(str(o)+': '+prince,'\\tvsini =',round(vsini,3),'km/s')\n",
    "                x,y,x_new,y_new,xnew,ynew=float('nan'),float('nan'),float('nan'),float('nan'),float('nan'),float('nan')\n",
    "            #new vsini from fitted func, only if a little off the chart\n",
    "            elif h['wid']>np.min(width)-2. and h['wid']<np.max(width)+2.:\n",
    "                X,Y=width,V2 #+vsini0\n",
    "                points=np.array([(X[i],Y[i]) for i in range(len(X))])\n",
    "                # get x and y vectors\n",
    "                x = points[:,0]\n",
    "                y = points[:,1]\n",
    "                # calculate polynomial\n",
    "                z = np.polyfit(x, y, 2)\n",
    "                f = np.poly1d(z)\n",
    "                # calculate new x's and y's\n",
    "                x_new = np.linspace(np.min(width)-2, np.max(width)+2, len(width))\n",
    "                y_new = f(x_new)\n",
    "                xnew=h['wid']\n",
    "                ynew=f(xnew)\n",
    "                ###\n",
    "                vsinibroad=ynew\n",
    "                vsini=vrotcombo(vsini0,vsinibroad)\n",
    "                fitpass='y'\n",
    "                if prin=='y':\n",
    "                    print(str(o)+': '+prince,'\\tvsini =',round(vsini,3),'km/s')\n",
    "            else:\n",
    "                vsinibroad=float('nan')\n",
    "                vsini=float('nan')\n",
    "                if prin=='y':\n",
    "                    print(str(o)+': '+prince,'\\tvsini =',round(vsini,3), \"km/s - Skipping order\",o,'for vsini.')\n",
    "                x,y,x_new,y_new,xnew,ynew=float('nan'),float('nan'),float('nan'),float('nan'),float('nan'),float('nan')\n",
    "                fitpass='n'\n",
    "            vsinis.append(vsini)\n",
    "\n",
    "        except ValueError:\n",
    "            print('Failed to fit Gaussian to order '+str(o)+'.')\n",
    "            rvs.append(np.float('nan'))\n",
    "            vsinis.append(np.float('nan'))\n",
    "\n",
    "        if plotyn=='y': #o==24 and \n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.plot(width,V2,marker='o')\n",
    "            plt.scatter(h['wid'],vsinibroad,color='red')\n",
    "            plt.ylabel('vsini broadening')\n",
    "            plt.xlabel('width')\n",
    "            plt.title('From '+stdname+', vsini_std = '+str(round(vsini0,2))+' km/s')\n",
    "            plt.plot(x,y,'o', x_new, y_new,color='green',ls='--',lw=1.5)\n",
    "            plt.scatter(xnew,ynew,color='red')\n",
    "            if fitpass=='n':\n",
    "                plt.scatter(h['wid'],vsini,marker='x',lw=1.2,color='black',s=90)\n",
    "\n",
    "    #Remove outliers based on median and std of middle quartile\n",
    "    rvx=rvs #only 2 for Goodman, don't drop any \"orders\"\n",
    "    #weighted rv\n",
    "    weights0x=1./np.array(svs0)**2.\n",
    "    #weights0x=np.array([weights0[i] for i in range(len(rvs)) if rvs[i]>rmin and rvs[i]<rmax])\n",
    "    #normalize the weights\n",
    "    weights0xn=weights0x/sum(weights0x)\n",
    "    #rv\n",
    "    rvxw=np.nansum(rvx*weights0xn)\n",
    "    rvxstd=np.nanstd(rvx) # !!!!! standard\n",
    "\n",
    "    #vsini\n",
    "    vsinix=vsinis #np.array([vsinis[i] for i in range(len(rvs)) if rvs[i]>rmin and rvs[i]<rmax])\n",
    "    #normalize the weights\n",
    "    weights0xx=[weights0x[i] if np.isnan(vsinix[i])==False else float('nan') for i in range(len(weights0x))] #keep if vsini any good\n",
    "    weights0xxn=weights0xx/np.nansum(weights0xx)\n",
    "    vsinixw=np.nansum(vsinix*weights0xxn)\n",
    "    if np.isnan(vsini0err)==True:\n",
    "        vsini0err=1. #arbitrary\n",
    "        print('Unknown vsini_std_err set to 1. km/s.')\n",
    "    vsinixstd=np.nanstd(vsinix) # !!!!! standard\n",
    "    if vsinixw==0.0: #if no width-to-vsini plots worked, then probably vsini_target < vsini_std, and this result should be thrown out.\n",
    "        vsinixw2=float('nan')\n",
    "        vsinixstd2=float('nan')\n",
    "        vsiniflag='(NULL AND VOID, vsini_std > vsini_target)'\n",
    "    elif vsinixstd<0.1: #arbitrary\n",
    "        vsinixw2=vsinixw\n",
    "        vsinixstd2=0.1\n",
    "        vsiniflag='(vsinierr adjusted to 0.1 km/s)'\n",
    "    else:\n",
    "        vsinixw2=vsinixw\n",
    "        vsinixstd2=vsinixstd\n",
    "        vsiniflag=''\n",
    "    vsinilen=len([a for a in vsinix if np.isnan(a)==False])\n",
    "    print('\\nWeighted rv of',name,' (',stdspt,') :',rvxw,'+-',rvxstd,'km/s')\n",
    "    print('Weighted vsini of',name,' (',stdspt,') :',vsinixw,'+-',vsinixstd,'km/s',vsiniflag,'\\n')\n",
    "\n",
    "    return stdname,stdspt,rvxw,rvxstd,vsinixw2,vsinixstd2,bados,vsinilen,skipedge0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#name', 'spt', 'V', 'texp', 'ra', 'dec', 'vsini', 'vsinierr', 'rv', 'rverr', 'vsiniref', 'rvref', 'sptref', 'notes']\n"
     ]
    }
   ],
   "source": [
    "# One target against multiple standards:\n",
    "mname,mnote=opendat(cdir,'standards/standards_metadata.dat',('#name','notes'))\n",
    "def fitvsini(name,spt,rvcent0=0,vsinistart0=0,skipedge0=0,prin='n',plotyn='n'): #target name, spectral type (including lum. class). Need standards all loaded up.\n",
    "    print(name,spt)\n",
    "    print('\\nMeasuring rv and vsini.')\n",
    "    svalue=sval(spt)\n",
    "    #take all standards within 2 sval of svalue. Also, don't use high-vsini or extreme rad vel standards.\n",
    "    standards=[stds[i] for i in range(len(stds)) if abs(ssval[i]-svalue)<=2 and 'HIGHVSINI' not in mnote[mname.index(stds[i])] and 'EXTREMERADVEL' not in mnote[mname.index(stds[i])]]\n",
    "    num=len(standards)\n",
    "    if num==0:\n",
    "        print('No suitable standards found. No measurements can be made.')\n",
    "    else:\n",
    "        print('Standards:',standards,'\\n')\n",
    "    stdnames,stdspts,rvs,rverrs,vsinis,vsinierrs,bados,vsinilen,skipage=['',]*num,['',]*num,['',]*num,['',]*num,['',]*num,['',]*num,['',]*num,['',]*num,['',]*num\n",
    "    skipedgestd=0\n",
    "    for i in range(num):\n",
    "        done='n'\n",
    "        print(name,standards[i])\n",
    "        while done=='n':\n",
    "            try:\n",
    "                stdnames[i],stdspts[i],rvs[i],rverrs[i],vsinis[i],vsinierrs[i],bados[i],vsinilen[i],skipage[i]=fitvsinilite(name,standards[i],rvcent0,vsinistart0,skipedgestd,prin=prin,plotyn=plotyn,pltcc=plotyn) #'target','standard'\n",
    "                done='y'\n",
    "            except PE.PyAValError:\n",
    "                print('Fitvsini failed, increasing skipedge...')\n",
    "                skipedgestd+=5\n",
    "    flags=[stdnames[i] if abs(rvs[i]-np.median(rvs))>np.std(rvs) and abs(rvs[i]-np.median(rvs))>0.3 else '0' for i in range(len(rvs))]\n",
    "    rv=erm(rvs,rverrs)[0]\n",
    "    rverr=np.max([np.std(rvs),erm(rvs,rverrs)[1]]) #spread of rvs is preferred uncert, while erm uncert is lower limit\n",
    "    vsini=erm(vsinis,vsinierrs)[0]\n",
    "    vsinierr=np.max([np.std(vsinis),erm(vsinis,vsinierrs)[1]]) # \"\" for vsinis\n",
    "    \n",
    "    #favor vsini measurements that utilize more orders:\n",
    "    #combined by # of orders utilized:\n",
    "    #vsini=np.nansum(np.array(vsinis)*np.array(vsinilen)/np.nansum(vsinilen))\n",
    "    #vsinierr=np.sqrt(np.nansum((np.array(vsinierrs)*np.array(vsinilen)/np.nansum(vsinilen)**2.)))\n",
    "    \n",
    "    if num>0:\n",
    "        bestspt=stdspts[np.argmin(rverrs)]\n",
    "    else:\n",
    "        bestspt='nan' #for no similar good standards\n",
    "    return name,rv,rverr,vsini,vsinierr,bestspt,stdnames,stdspts,rvs,rverrs,vsinis,vsinierrs,bados,vsinilen,flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Radial Velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure all targets, and standards too\n",
    "#Metadata for targets:\n",
    "targnames,targspts=opendat('','file.dat',['#name','spt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs=fnamest\n",
    "\n",
    "#blank lists, for collecting results:\n",
    "whichnames,whichstds,stdrvs,stdrverrs,stdvsinis,stdvsinierrs,stdbestspts,stdflags,vsinilens=[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "t0=time.time() \n",
    "for i in range(len(targs)):\n",
    "    if i%10==0:\n",
    "        t1 = time.time()\n",
    "        print('Working on '+str(i+1)+' of '+str(len(stds))+', time elapsed:',t1-t0,'s')\n",
    "    Name=targs[i]\n",
    "    if 'CG' not in Name:\n",
    "        SpT=refspt(targs)\n",
    "    else:\n",
    "        SpT=targspts[targnames.index(Name)]\n",
    "    #if sval(stdSpT)<=46:    #45: for SpT A5 and later\n",
    "    #print(stdName,stdSpT)\n",
    "    print('\\n---\\n')\n",
    "    whichname,rv,rverr,vsini,vsinierr,bestspt,stdnames,stdspts,rvs,rverrs,vsinis,vsinierrs,bados,vsinilen,flags=fitvsini(Name,SpT)\n",
    "    whichnames.append(whichname)\n",
    "    whichstds.append(stdnames)\n",
    "    stdrvs.append(rvs)\n",
    "    stdrverrs.append(rverrs)\n",
    "    stdvsinis.append(vsinis)\n",
    "    stdvsinierrs.append(vsinierrs)\n",
    "    stdbestspts.append(bestspt)\n",
    "    stdflags.append(flags)\n",
    "    vsinilens.append(vsinilen)\n",
    "    print()\n",
    "t1 = time.time()\n",
    "print('Time elapsed:',(t1-t0)/3600.,'hr.') #Took ~5 hr for 99 spectral standards.\n",
    "#Trial 1: Time elapsed: 12000.443932294846 s = 3h 20m\n",
    "#Trial 2: 3h 7m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
